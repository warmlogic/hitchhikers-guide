{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features, Labels, Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple static feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_feature(filename='gender_female.csv'):\n",
    "    \"\"\" Reads in a CSV, drops NAs, returns the DataFrame. \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.dropna(how='any')\n",
    "    \n",
    "    return df.set_index('entity_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_female</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gender_female\n",
       "entity_id               \n",
       "309                  1.0\n",
       "324                  1.0\n",
       "48                   1.0\n",
       "210                  0.0\n",
       "180                  1.0"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_gender = gender_feature()\n",
    "my_gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A temporal feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def incident_aggregation(as_of_date, agg_col, date_col, time_delta, \n",
    "                         agg_funcs, filename='incidents.csv'):\n",
    "    \"\"\"\n",
    "    Reads and aggregates a CSV file over a date range.\n",
    "    \n",
    "    Args:\n",
    "        as_of_date (datetime): End of the aggregation window (excluded).\n",
    "        agg_col (str): Name of the column for aggregation.\n",
    "        date_col (str): Name of the column that gives knowledge dates for \n",
    "                        the values in agg_col.\n",
    "        time_delta (pd.Timedelta): Time range. Gives the time \n",
    "                                   window preceding the as_of_date over\n",
    "                                   which we aggregate.\n",
    "        agg_funcs (dict): A dictionary that maps column names to functions.\n",
    "                          The functions will be applied to the groupby, \n",
    "                          and the resulting dataframe contains columns\n",
    "                          named like <key>_<timedelta>.\n",
    "        filename (str): Path to the CSV that should be aggregated. The \n",
    "                       CSV must contain an entity_id column, as well as \n",
    "                       the columns given by agg_col and date_col.\n",
    "        \n",
    "    Returns (pd.DataFrame): A dataframe, uniquely indexed by entity_id,\n",
    "                            with columns that contain the aggregations\n",
    "                            from agg_funcs. \n",
    "    \"\"\"\n",
    "    \n",
    "    # read the CSV\n",
    "    df = pd.read_csv(filename)\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    # restrict to data in aggregation window\n",
    "    df = df.loc[df[date_col] < as_of_date,:]\n",
    "    df = df.loc[df[date_col] >= (as_of_date-time_delta),:]\n",
    "    \n",
    "    # add as_of_date to the index\n",
    "    df['as_of_date'] = as_of_date\n",
    "    df = df.set_index(['entity_id','as_of_date'])\n",
    "    \n",
    "    # just some formatting for naming the columns\n",
    "    nice_timedelta_str = str(time_delta).replace('00:00:00','').replace(' ','')\n",
    "    agg_funcs = {k+'_'+nice_timedelta_str: v for k,v in agg_funcs.items()}\n",
    "    \n",
    "    # aggregate by entity_id and apply the functions\n",
    "    return df[agg_col].groupby(level=[0,1]).agg(agg_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_agg = incident_aggregation(pd.to_datetime('2016-01-01'),\n",
    "                             'incident_type',\n",
    "                             'incident_date',\n",
    "                              pd.Timedelta(365,'d'), \n",
    "                              {'count_neglects': lambda x: sum(x=='neglect_of_duty'),\n",
    "                              'count_conduct': lambda x: sum(x=='conduct_unbecoming')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count_conduct_365days</th>\n",
       "      <th>count_neglects_365days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count_conduct_365days  count_neglects_365days\n",
       "entity_id as_of_date                                               \n",
       "0         2016-01-01                      2                       1\n",
       "1         2016-01-01                      2                       1\n",
       "2         2016-01-01                      1                       0\n",
       "3         2016-01-01                      1                       2\n",
       "4         2016-01-01                      3                       0"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_aggregation(as_of_date, time_delta, filename='incidents.csv'):\n",
    "    \"\"\" Find if an entity has a 'discipline' or 'conduct_unbecoming' incident\n",
    "        that is decided as sustained.\n",
    "    Args:\n",
    "        as_of_date (datetime): Beginning of the aggregation window (included).\n",
    "        time_delta (pd.Timedelta): Time range. Gives the time \n",
    "                                   window following the as_of_date over\n",
    "                                   which we aggregate.\n",
    "        filename (str): Path to the incidents CSV, which contains\n",
    "                        entity_id, incident type and date, and \n",
    "                        decision with date.\n",
    "    Returns (pd.Series):\n",
    "        A boolean series, indexed uniquely by entity_id and as_of_date,\n",
    "        giving if the entity had at least one sustained disciplinary\n",
    "        or conduct_unbecoming event that fell within the time window.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the CSV\n",
    "    df = pd.read_csv(filename, parse_dates=['incident_date','decision_date'])\n",
    "        \n",
    "    # restrict to incidents after the as_of_date\n",
    "    df = df.loc[df.incident_date>=as_of_date,:]\n",
    "    \n",
    "    # restrict to decisions in the time window\n",
    "    df = df.loc[df.decision_date<(as_of_date+time_delta),:]\n",
    "\n",
    "    # add the as_of_date to the index\n",
    "    df['as_of_date'] = as_of_date\n",
    "    df = df.set_index(['entity_id','as_of_date'])\n",
    "    \n",
    "    # binarize\n",
    "    df['adverse_incident'] = df.incident_type.isin(['discipline','conduct_unbecoming'])\\\n",
    "                             &(df.decision=='sustained')\n",
    "    \n",
    "    # aggregate and return\n",
    "    return df.adverse_incident.groupby(level=[0,1]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_labels = label_aggregation(pd.to_datetime('2016-01-01'), pd.Timedelta(90,'d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity_id  as_of_date\n",
       "2          2016-01-01     True\n",
       "3          2016-01-01    False\n",
       "8          2016-01-01    False\n",
       "9          2016-01-01    False\n",
       "10         2016-01-01    False\n",
       "Name: adverse_incident, dtype: bool"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_gender['as_of_date'] = pd.to_datetime('2016-01-01')\n",
    "my_gender = my_gender.set_index(['as_of_date'], append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>adverse_incident</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>count_conduct_365days</th>\n",
       "      <th>count_neglects_365days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     adverse_incident  gender_female  count_conduct_365days  \\\n",
       "entity_id as_of_date                                                          \n",
       "2         2016-01-01             True            0.0                    1.0   \n",
       "3         2016-01-01            False            0.0                    1.0   \n",
       "8         2016-01-01            False            1.0                    3.0   \n",
       "9         2016-01-01            False            0.0                    1.0   \n",
       "10        2016-01-01            False            0.0                    1.0   \n",
       "\n",
       "                      count_neglects_365days  \n",
       "entity_id as_of_date                          \n",
       "2         2016-01-01                     0.0  \n",
       "3         2016-01-01                     2.0  \n",
       "8         2016-01-01                     2.0  \n",
       "9         2016-01-01                     0.0  \n",
       "10        2016-01-01                     2.0  "
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = my_labels.to_frame().join(my_gender, how='left')\\\n",
    "                              .join(my_agg, how='left')\n",
    "    \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But clearly, some entities are missing...\n",
    "Make a table of 'active' entities for the given date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def active_officers(as_of_date, filename='patrol_duty.csv'):\n",
    "    \"\"\"Check if an officer is on patrol duty for the as_of_date.\"\"\"\n",
    "    \n",
    "    # read CSV\n",
    "    df = pd.read_csv(filename, parse_dates=['start_date','end_date'])\n",
    "    \n",
    "    # check if as_of_date falls between start and end date of duty\n",
    "    df['active'] = (df.start_date<=as_of_date)&(df.end_date>=as_of_date)\n",
    "    \n",
    "    df['as_of_date'] = as_of_date\n",
    "    df = df.set_index(['entity_id','as_of_date'])\n",
    "    \n",
    "    return df[df.active==True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_active = active_officers(pd.to_datetime('2016-01-01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now index into the dataset with our new entity list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>adverse_incident</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>count_conduct_365days</th>\n",
       "      <th>count_neglects_365days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     adverse_incident  gender_female  count_conduct_365days  \\\n",
       "entity_id as_of_date                                                          \n",
       "0         2016-01-01              NaN            NaN                    NaN   \n",
       "2         2016-01-01             True            0.0                    1.0   \n",
       "3         2016-01-01            False            0.0                    1.0   \n",
       "13        2016-01-01              NaN            NaN                    NaN   \n",
       "15        2016-01-01              NaN            NaN                    NaN   \n",
       "\n",
       "                      count_neglects_365days  \n",
       "entity_id as_of_date                          \n",
       "0         2016-01-01                     NaN  \n",
       "2         2016-01-01                     0.0  \n",
       "3         2016-01-01                     2.0  \n",
       "13        2016-01-01                     NaN  \n",
       "15        2016-01-01                     NaN  "
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[my_active,:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to coalesce / impute!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A slightly nicer label fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_aggregation(as_of_dates, time_delta, filename='incidents.csv'):\n",
    "    \"\"\" Find if an entity has a 'discipline' or 'conduct_unbecoming' incident\n",
    "        that is decided as sustained.\n",
    "    Args:\n",
    "        as_of_dates ([datetime]): List of beginnings of the aggregation \n",
    "                                  windows (included).\n",
    "        time_delta (pd.Timedelta): Time range. Gives the time \n",
    "                                   window following the as_of_date over\n",
    "                                   which we aggregate.\n",
    "        filename (str): Path to the incidents CSV, which contains\n",
    "                        entity_id, incident type and date, and \n",
    "                        decision with date.\n",
    "    Returns (pd.Series):\n",
    "        A boolean series, indexed uniquely by entity_id and as_of_date,\n",
    "        giving if the entity had at least one sustained disciplinary\n",
    "        or conduct_unbecoming event that fell within the time window.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the CSV\n",
    "    df = pd.read_csv(filename, parse_dates=['incident_date','decision_date'])\n",
    "    \n",
    "    if len(set(as_of_dates))!=len(as_of_dates):\n",
    "        raise ValueError(\"As of dates need to be unique!\")\n",
    "        \n",
    "    as_of_dates = sorted(as_of_dates)\n",
    "    \n",
    "    # let's be cautious here already and do a sanity check\n",
    "    for idx, aod in enumerate(as_of_dates[:-1]):\n",
    "        if aod+time_delta >= as_of_dates[idx+1]:\n",
    "            warnings.warn(\"Your label windows will overlap!\")\n",
    "        \n",
    "    dfs = []\n",
    "    \n",
    "    # go over all the dates\n",
    "    for as_of_date in as_of_dates:\n",
    "        \n",
    "        # restrict to incidents after the as_of_date\n",
    "        this_df = df.loc[df.incident_date>=as_of_date,:]\n",
    "\n",
    "        # restrict to decisions in the time window\n",
    "        this_df = this_df.loc[this_df.decision_date<(as_of_date+time_delta),:]\n",
    "\n",
    "        # add the as_of_date to the index\n",
    "        this_df['as_of_date'] = as_of_date\n",
    "        this_df = this_df.set_index(['entity_id','as_of_date'])\n",
    "\n",
    "        # binarize\n",
    "        this_df['adverse_incident'] = this_df.incident_type.isin(['discipline','conduct_unbecoming'])\\\n",
    "                                      &(this_df.decision=='sustained')\n",
    "            \n",
    "        dfs.append(this_df.adverse_incident.groupby(level=[0,1]).max())\n",
    "    \n",
    "    # concat and return\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_labels = label_aggregation([pd.to_datetime('2016-01-01'),\n",
    "                               pd.to_datetime('2016-05-01')],\n",
    "                              pd.Timedelta(90,'d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity_id  as_of_date\n",
       "2          2016-01-01     True\n",
       "3          2016-01-01    False\n",
       "8          2016-01-01    False\n",
       "9          2016-01-01    False\n",
       "10         2016-01-01    False\n",
       "Name: adverse_incident, dtype: bool"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-01-01', '2016-05-01'], dtype='datetime64[ns]', name='as_of_date', freq=None)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_labels.index.levels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... and slightly nicer active-officer fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def active_officers(as_of_dates, filename='patrol_duty.csv'):\n",
    "    \"\"\"Check if an officer is on patrol duty for the as_of_date.\"\"\"\n",
    "    \n",
    "    # read CSV\n",
    "    df = pd.read_csv(filename, parse_dates=['start_date','end_date'])\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for as_of_date in as_of_dates:\n",
    "\n",
    "        # check if as_of_date falls between start and end date of duty\n",
    "        this_active = (df.start_date<=as_of_date)&(df.end_date>=as_of_date)\n",
    "\n",
    "        df['as_of_date'] = as_of_date\n",
    "        \n",
    "        dfs.append(df[this_active==True].set_index(['entity_id','as_of_date']))\n",
    "    \n",
    "    return pd.concat(dfs).sort_index().index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_active = active_officers([pd.to_datetime('2016-01-01'),\n",
    "                             pd.to_datetime('2016-05-01')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[[0, 2, 3, 13, 15, 18, 21, 29, 32, 34, 35, 37, 42, 43, 48, 52, 54, 57, 61, 62, 65, 69, 73, 75, 79, 81, 107, 108, 109, 114, 115, 116, 121, 133, 137, 138, 140, 143, 145, 146, 151, 152, 153, 155, 156, 164, 171, 179, 187, 194, 195, 197, 206, 208, 210, 213, 218, 220, 223, 227, 229, 232, 243, 248, 255, 256, 259, 260, 265, 273, 287, 297, 301, 305, 307, 308, 310, 318, 327, 334, 337, 339, 343, 345, 372, 374, 380, 384, 386, 387, 390, 396, 400, 402, 403, 404, 410, 411, 412, 415, 418, 425, 427, 432, 433, 434, 440, 448, 453, 455, 463, 468, 478, 483, 494], [2016-01-01 00:00:00, 2016-05-01 00:00:00]],\n",
       "           labels=[[0, 0, 1, 2, 2, 3, 3, 4, 5, 5, 6, 7, 7, 8, 8, 9, 10, 10, 11, 11, 12, 12, 13, 14, 14, 15, 15, 16, 17, 18, 18, 19, 19, 20, 21, 21, 22, 22, 23, 24, 24, 25, 26, 27, 28, 28, 29, 29, 30, 30, 31, 32, 32, 33, 33, 34, 34, 35, 36, 36, 37, 38, 38, 39, 40, 41, 42, 42, 43, 43, 44, 44, 45, 45, 46, 47, 47, 48, 49, 49, 50, 50, 51, 52, 52, 53, 54, 54, 55, 56, 56, 57, 58, 59, 60, 60, 61, 62, 63, 64, 65, 65, 66, 67, 67, 68, 68, 69, 70, 70, 71, 72, 72, 73, 73, 74, 74, 75, 76, 76, 77, 77, 78, 79, 79, 80, 80, 81, 81, 82, 83, 84, 85, 86, 86, 87, 87, 88, 88, 89, 89, 90, 91, 92, 92, 93, 94, 95, 96, 97, 97, 98, 98, 99, 100, 101, 102, 103, 104, 105, 105, 106, 106, 107, 108, 109, 109, 110, 110, 111, 111, 112, 112, 113, 113, 114, 114], [0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]],\n",
       "           names=['entity_id', 'as_of_date'])"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the Split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_splitter(split_dates, label_time_delta, label_fetcher, feature_fetchers):\n",
    "    \"\"\"TODO: Write nice documentation. Always!\"\"\"\n",
    "    \n",
    "    test_as_of_dates = [aod for aod, usefor in split_dates if usefor=='test']\n",
    "    train_as_of_dates = [aod for aod, usefor in split_dates if usefor=='train']\n",
    "    as_of_dates = list(zip(*split_dates))[0]\n",
    "    \n",
    "    # TODO: check that the as_of_dates are unique\n",
    "    \n",
    "    # check that the train/test splits are well-separated\n",
    "    if max(train_as_of_dates) + label_time_delta >= min(test_as_of_dates):\n",
    "        raise ValueError(\"Your train and test label windows overlap!\")\n",
    "        \n",
    "    # fetch the index of active officers - make DF, beacuse Pandas isn't nice here\n",
    "    actives = pd.DataFrame(index=active_officers(as_of_dates))\n",
    "        \n",
    "    # fetch the DF with labels\n",
    "    labels = label_fetcher(as_of_dates, label_time_delta)\n",
    "    \n",
    "    # subset (or superset!) the labels to active entities\n",
    "    dataset = actives.join(labels, how='left')\n",
    "    \n",
    "    # now join in all the features\n",
    "    for ff in feature_fetchers:\n",
    "        \n",
    "        these_feats = []\n",
    "        \n",
    "        # first, concatenate the various as-of-dates per feature\n",
    "        # TODO: this should be handled by the features, really!\n",
    "        for as_of_date in as_of_dates:\n",
    "                        \n",
    "            # note: You could do some **kwargs magic here, and have every feature accept arbitrary arguments.\n",
    "            #       Nice if you want to handle a single config dict!\n",
    "            these_feats.append(ff(as_of_date))\n",
    "            \n",
    "        dataset = dataset.join(pd.concat(these_feats), how='left')\n",
    "    \n",
    "    # let's make an aux with test/train information:\n",
    "    \n",
    "    # small dataframe with just dates --> usefor\n",
    "    only_dates = pd.DataFrame(split_dates,\n",
    "                              columns=['as_of_date', 'usefor']).set_index('as_of_date')\n",
    "    \n",
    "    # blow up that dataframe with the dataset index (as_of_dates)\n",
    "    aux = only_dates.loc[dataset.index.get_level_values(1),:]\n",
    "    \n",
    "    # share index\n",
    "    aux.index = dataset.index\n",
    "        \n",
    "    return dataset, aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can grab training/testing data with many as-of-dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's wrap the gender feature - it's nice to have even static features mirror the as-of-date\n",
    "def nicer_gender(as_of_date):\n",
    "    df = gender_feature()\n",
    "    df['as_of_date'] = as_of_date\n",
    "    return df.set_index('as_of_date', append=True)\n",
    "\n",
    "\n",
    "my_split_dates = [(pd.to_datetime('2016-01-01'), 'train'), \n",
    "                  (pd.to_datetime('2016-04-30') , 'train'), \n",
    "                  (pd.to_datetime('2016-08-01'), 'test')]\n",
    "\n",
    "my_feature_fetchers = [lambda aod: incident_aggregation(aod, 'incident_type', 'incident_date', \n",
    "                                                        pd.Timedelta(90,'d'), \n",
    "                                                         {'count_neglects': lambda x: sum(x=='neglect_of_duty'),\n",
    "                                                          'count_conduct': lambda x: sum(x=='conduct_unbecoming')}),\n",
    "                       lambda aod: incident_aggregation(aod, 'decision', 'decision_date', \n",
    "                                                        pd.Timedelta(190,'d'), \n",
    "                                                         {'count_decision_other': lambda x: sum(x=='other')}),\n",
    "                       nicer_gender\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m, aux = train_test_splitter(my_split_dates,\n",
    "                             label_time_delta=pd.Timedelta(90,'d'),\n",
    "                             label_fetcher=label_aggregation,\n",
    "                             feature_fetchers=my_feature_fetchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>adverse_incident</th>\n",
       "      <th>count_conduct_90days</th>\n",
       "      <th>count_neglects_90days</th>\n",
       "      <th>count_decision_other_190days</th>\n",
       "      <th>gender_female</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-30</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     adverse_incident  count_conduct_90days  \\\n",
       "entity_id as_of_date                                          \n",
       "0         2016-01-01              NaN                   1.0   \n",
       "          2016-04-30            False                   NaN   \n",
       "          2016-08-01              NaN                   1.0   \n",
       "2         2016-01-01             True                   NaN   \n",
       "3         2016-01-01            False                   0.0   \n",
       "\n",
       "                      count_neglects_90days  count_decision_other_190days  \\\n",
       "entity_id as_of_date                                                        \n",
       "0         2016-01-01                    0.0                           0.0   \n",
       "          2016-04-30                    NaN                           0.0   \n",
       "          2016-08-01                    2.0                           0.0   \n",
       "2         2016-01-01                    NaN                           0.0   \n",
       "3         2016-01-01                    1.0                           0.0   \n",
       "\n",
       "                      gender_female  \n",
       "entity_id as_of_date                 \n",
       "0         2016-01-01            0.0  \n",
       "          2016-04-30            0.0  \n",
       "          2016-08-01            0.0  \n",
       "2         2016-01-01            0.0  \n",
       "3         2016-01-01            0.0  "
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>usefor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-30</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-01</th>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     usefor\n",
       "entity_id as_of_date       \n",
       "0         2016-01-01  train\n",
       "          2016-04-30  train\n",
       "          2016-08-01   test\n",
       "2         2016-01-01  train\n",
       "3         2016-01-01  train"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>adverse_incident</th>\n",
       "      <th>count_conduct_90days</th>\n",
       "      <th>count_neglects_90days</th>\n",
       "      <th>count_decision_other_190days</th>\n",
       "      <th>gender_female</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-30</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     adverse_incident  count_conduct_90days  \\\n",
       "entity_id as_of_date                                          \n",
       "0         2016-01-01              NaN                   1.0   \n",
       "          2016-04-30            False                   NaN   \n",
       "2         2016-01-01             True                   NaN   \n",
       "3         2016-01-01            False                   0.0   \n",
       "          2016-04-30              NaN                   0.0   \n",
       "\n",
       "                      count_neglects_90days  count_decision_other_190days  \\\n",
       "entity_id as_of_date                                                        \n",
       "0         2016-01-01                    0.0                           0.0   \n",
       "          2016-04-30                    NaN                           0.0   \n",
       "2         2016-01-01                    NaN                           0.0   \n",
       "3         2016-01-01                    1.0                           0.0   \n",
       "          2016-04-30                    0.0                           0.0   \n",
       "\n",
       "                      gender_female  \n",
       "entity_id as_of_date                 \n",
       "0         2016-01-01            0.0  \n",
       "          2016-04-30            0.0  \n",
       "2         2016-01-01            0.0  \n",
       "3         2016-01-01            0.0  \n",
       "          2016-04-30            0.0  "
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.loc[aux[aux.usefor=='train'].index,:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODOs**:\n",
    "- imputation for labels and features\n",
    "- NaN-checker: Throw error if too many rows are NaN. And/or: Make sure all requested as-of-dates actually get returned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
